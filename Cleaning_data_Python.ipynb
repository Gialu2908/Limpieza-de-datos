{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning_data_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1e8_Ocqw-PXiIQ5NB5yEhisSTztddXrF4",
      "authorship_tag": "ABX9TyN+vE3FVeYLsZoKwpePi8db",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SandyAtencio/Cleaning_data_Python_Part_1/blob/master/Cleaning_data_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMDCXP8at6us"
      },
      "source": [
        "### **‚ö†Ô∏èüòìProblemas comunes de datos**\n",
        "A continuacion vamos a trabajar sobre un dataset que contiene datos sucios, al cual le vamos a aplicar tecnicas de limpieza como:\n",
        "\n",
        "‚úîÔ∏èConversion de tipos de datos<br>\n",
        "‚úîÔ∏èEliminacion de datos duplicados para evitar el doble conteo<br>\n",
        "‚úîÔ∏èRestrinccion de rangos para evitar datos futuros incoherentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "719dxmDl21d-"
      },
      "source": [
        "**üßæInformacion del Dataset**<br>\n",
        "El dataset que estaremos trabajando comprende informacion sobre las estaciones de inicio y finalizaci√≥n, la duraci√≥n del viaje y cierta informaci√≥n para el usuario de un servicio de bicicletas compartidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaA6DmJlty0B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fnVlgvD90i3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffa86ba-8db4-40d3-aa40-2c6c62b6417d"
      },
      "source": [
        "df_ride = pd.read_csv(\"ride_sharing_new.csv\")\n",
        "#veamos que tiene el dataset\n",
        "df_ride.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76 entries, 0 to 75\n",
            "Data columns (total 12 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   ride_id          76 non-null     int64 \n",
            " 1   duration         76 non-null     object\n",
            " 2   station_A_id     76 non-null     int64 \n",
            " 3   station_A_name   76 non-null     object\n",
            " 4   station_B_id     76 non-null     int64 \n",
            " 5   station_B_name   76 non-null     object\n",
            " 6   bike_id          76 non-null     int64 \n",
            " 7   user_type        76 non-null     int64 \n",
            " 8   user_birth_year  76 non-null     int64 \n",
            " 9   user_gender      76 non-null     object\n",
            " 10  tire_sizes       76 non-null     int64 \n",
            " 11  ride_date        76 non-null     object\n",
            "dtypes: int64(7), object(5)\n",
            "memory usage: 7.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vki4T4l94SmC"
      },
      "source": [
        "La columna `user_type` contiene informaci√≥n sobre si un usuario est√° viajando gratis y toma los siguientes valores:\n",
        "\n",
        "üö¥‚Äç‚ôÇÔ∏è `1` de viaje gratis <br>\n",
        "üö¥‚Äç‚ôÇÔ∏è `2` de pago por viaje <br>\n",
        "üö¥‚Äç‚ôÇÔ∏è `3` de suscriptores mensuales <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMZrkMJA07Ex",
        "outputId": "3a831df7-0298-48f0-93b2-623ff97759d8"
      },
      "source": [
        "#utilizamos describe para ver el resumen estadistico de los datos de la columna user_type\n",
        "df_ride['user_type'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    76.000000\n",
              "mean      1.881579\n",
              "std       0.692187\n",
              "min       1.000000\n",
              "25%       1.000000\n",
              "50%       2.000000\n",
              "75%       2.000000\n",
              "max       3.000000\n",
              "Name: user_type, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEj78tsU8RRO"
      },
      "source": [
        "üëÅÔ∏è‚Äçüó®Ô∏è Al observar las estadisticas resumidas de la columna `user_type` vemos que  tiene un conjunto finito de valores posibles que representan agrupaciones de datos, por ende, debemos convertir esta columna a tipo categor√≠a."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE0XLam39OJo",
        "outputId": "b386fa93-3ab7-40e3-e601-5832f7756608"
      },
      "source": [
        "#podemos a cambiar el tipo de dato con astype, y se lo asignamos a la nueva columna\n",
        "df_ride['user_type'] = df_ride['user_type'].astype('category')\n",
        "\n",
        "#Para asegurarnos que la conversion fue correcta utilizamos la declaracion assert\n",
        "assert df_ride['user_type'].dtype == 'category'\n",
        "\n",
        "#y nuevamente observamos las estadisticas resumidas de la nueva columna, y podemos ver que\n",
        "#el resultado cambia al tratarse de una variable categorica\n",
        "print(df_ride['user_type'].describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count     76\n",
            "unique     3\n",
            "top        2\n",
            "freq      39\n",
            "Name: user_type, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSEvd6zj9rSp"
      },
      "source": [
        "üßπAhora bien, siguiendo con nuestra limpieza debemos evitar la inconsistencia de tipo de datos, es decir, debemos asesorarnos que los datos de tipo numericos sean numericos y asi sucesivamente con los demas datos. Esto se hace con el fin de que las operaciones matematicas que querramos realizar sobre esos datos arrojen resultados correctos y no erroneos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC16UVKFjoDF"
      },
      "source": [
        "Despues de haber revisado que contiene nuestro dataset, vamos a convertir la columna `durational` que es de tipo `object` a tipo `int`. Sin embargo, antes de eso, debemos asegurarnos de eliminar la palabra \"minutes\" para asi poderla convertir a numerica."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Mn6XqIEiWxc",
        "outputId": "9f1a7c14-b8ec-45b5-ac89-77fcc10c9973"
      },
      "source": [
        "#eliminamos la cadena minutes con el metodo strip \n",
        "df_ride['duration'] = df_ride['duration'].str.strip('minutes')\n",
        "\n",
        "#convertirmos duration a tipo int \n",
        "df_ride['duration'] = df_ride['duration'].astype('int')\n",
        "\n",
        "#Para asegurarnos que la conversion fue correcta utilizamos la declaracion assert\n",
        "assert df_ride['duration'].dtype == 'int'\n",
        "\n",
        "#Finalmente conocemos cual es la media de la columna duration_time\n",
        "print(df_ride['duration'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.776315789473685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElMyAnGAmb3W"
      },
      "source": [
        "Ahora vamos a trabajar sobre la columna `tire_size` la cual contiene datos sobre el tama√±o de los neum√°ticos de cada bicicleta. el tama√±o de los neum√°ticos de las bicicletas pueden ser 26\" 27\" y 29\" y son almacenados con un valor float.\n",
        "\n",
        "Actualmente se quieren reducir los costos de mantenimiento, por consiguiente el proveedor decidi√≥ establecer el tama√±o m√°ximo de neum√°ticos en 27. Respecto a esto  vamos a asegurarnos de que la columna  `tire_sizes` tenga el rango correcto para esto establecemos el nuevo limite superior 27\" para los tama√±os de neum√°ticos, y despues convirtimos la columna a tipo categoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZw1tN1coFlA",
        "outputId": "881c7fb4-ad96-4567-e5bc-4ee3a7ac9b29"
      },
      "source": [
        "#usamos loc para seleccionar todo esos registros mayores a 27 establecerle el limite superior que es 27\n",
        "df_ride.loc[df_ride['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
        "df_ride.head(10)\n",
        "\n",
        "#convetirmos a tipo categorico\n",
        "df_ride['tire_sizes'] = df_ride['tire_sizes'].astype('category')\n",
        "\n",
        "df_ride['tire_sizes'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count     76\n",
              "unique     2\n",
              "top       27\n",
              "freq      73\n",
              "Name: tire_sizes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NbMwkSMQiqz"
      },
      "source": [
        "üìÖ Ahora procederemos a encontrar todos los registros de la columna `ride_date` que tengan fechas futura, en caso de que si exista esta inconsistencia, lo que haremos sera establecer el valor maximo de esta columna con la fecha de hoy, pero antes de hacer eso debemos convetir a `ride_data` a tipo datetime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La68bT9b3f2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef86cd8-a742-47b5-83be-a39694d2663f"
      },
      "source": [
        "#convertimos a ride_date en tipo de dato datetime\n",
        "df_ride['ride_date'] = pd.to_datetime(df_ride['ride_date']).dt.date\n",
        "\n",
        "#almacenamos la fecha de hoy\n",
        "today = dt.date.today()\n",
        "\n",
        "# y por ultimo le aplicamos la fecha de hoy almacenada en today a aquellos registros con\n",
        "#fechas futuras, es decir con fechas superiores a hoy\n",
        "df_ride.loc[df_ride['ride_date'] > today, 'ride_date'] = today\n",
        "\n",
        "#mostramos la fecha maxima\n",
        "print(df_ride['ride_date'].max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7lhB-GQCMV9"
      },
      "source": [
        "LLego la hora, de encontrar los datos duplicados.\n",
        "Vamos a buscar que registros se encuentran duplicados en nuestro dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frqj6SM4BBDA",
        "outputId": "69ad60e3-fc12-45b5-e737-62cd793bd9fd"
      },
      "source": [
        "# Aqui buscamos duplicados \n",
        "duplicates = df_ride.duplicated('ride_id', keep = False)\n",
        "\n",
        "# ordenamos por la columna ride_id los registros duplicados obtenidos\n",
        "df_ride = df_ride[duplicates].sort_values( by = 'ride_id')\n",
        "\n",
        "# y por ultimo imprimimos los datos duplicados, mostramos \n",
        "#en cuales columnas estaban estos registros\n",
        "print(df_ride[['ride_id','duration','user_birth_year']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    ride_id  duration  user_birth_year\n",
            "21       33        11             1986\n",
            "38       33         6             1966\n",
            "52       55        13             1999\n",
            "64       55        10             1999\n",
            "72       71        11             1987\n",
            "73       71        11             1987\n",
            "74       89         9             1990\n",
            "75       89         9             1990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYKNFUBLDXbR"
      },
      "source": [
        "Despues de conocer los duplicados y las columnas que los almacenan hemos podido observar que hay filas duplicadas tanto completas como incompletas para algunos valores de la columna `ride_id`, con valores diferentes para las columnas `user_birth_year` y duration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4kfeAYqGClH"
      },
      "source": [
        "Entonces, lo que vamos hacer es primero tratar esas filas duplicadas eliminando primero los duplicados completos y luego fusionando las filas duplicadas incompletas en una, manteniendo el promedio de `duration` y el m√≠nimo `user_birth_year` para cada conjunto de filas duplicadas incompletas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebVKpWAqBiSc"
      },
      "source": [
        "# Eliminamos los duplicados completos en ride_sharing\n",
        "ride_dup = df_ride.drop_duplicates()\n",
        "\n",
        "# Creamos un diccionario de estadisticas para funciones de agregacion\n",
        "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
        "\n",
        "# Agrupamos por ride_id y calculamos las nuevas estadisticas\n",
        "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
        "\n",
        "# nuevamente buscamos valores duplicados\n",
        "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
        "duplicated_rides = ride_unique[duplicates == True]\n",
        "\n",
        "# y por ultimo nos aseguramos que se haya aplicado todo correctamente\n",
        "assert duplicated_rides.shape[0] == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhzEDfZ_WVfe"
      },
      "source": [
        "### **‚ùåüî°Problemas de texto y datos categ√≥ricos**\n",
        "\n",
        "En este espacio, vamos a corregir las incoherencias de hay con espacios en blanco y may√∫sculas en las etiquetas de las categor√≠as, tambien, vamos a contraer varias categor√≠as en una sola y cambiar el formato de las cadenas para mantener la coherencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vjk_DFmgLCV"
      },
      "source": [
        "**üßæInformacion del Dataset**<br>\n",
        "\n",
        "En este espacio trabajaremos con un dataset llamado `df_airlines` que contiene las respuestas de una encuesta que se le realizaron a los clientes de las aerolineas del aeropuerto de San Francisco. Este dataset tiene metadatos de vuelos, destinos, tiempos de espera, y tambien respuestas a preguntas de seguridad y sastifaccion\n",
        "\n",
        "Tambien trabajaremos con un dataset llamado `df_categories`, que contiene todos los valores posibles correctos para las columnas de la encuesta.\n",
        "\n",
        "‚úîÔ∏èUtilizaremos ambos dataset para encontrar respuestas de encuestas con valores inconsistentes y eliminarlas, con el fin de poder realizar de manera efectiva una combinaci√≥n externa e interna en ambos dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzRyz9LAfRfu",
        "outputId": "2b4c39a2-32d3-4273-fd4a-91243de345b6"
      },
      "source": [
        "df_categories = pd.read_csv('categories.csv')\n",
        "df_airlines = pd.read_csv('airlines_final.csv')\n",
        "\n",
        "#conozcamos cada una de las categorias\n",
        "print(df_categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      cleanliness           safety          satisfaction\n",
            "0           Clean          Neutral     Very satisfaction\n",
            "1         Average        Very safe               Neutral\n",
            "2  Somewhat clean    Somewhat safe    Somewhat satisfied\n",
            "3  Somewhat dirty      Very unsafe  Somewhat unsatisfied\n",
            "4          Dirty   Somewhat unsafe      Very unsatisfied\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os5m1T8Bh759",
        "outputId": "d4f6370d-eae0-4af8-b1c5-80821bf70e57"
      },
      "source": [
        "#Imprimimos los valores unicos de cada columna de la encuesta airlines\n",
        "#usando el metodo .unique()\n",
        "print('Cleanliness: ', df_airlines['cleanliness'].unique(), \"\\n\")\n",
        "print('Safety: ', df_airlines['safety'].unique(), \"\\n\")\n",
        "print('Satisfaction: ', df_airlines['satisfaction'].unique(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleanliness:  ['Clean' 'Average' 'Unacceptable' 'Somewhat clean' 'Somewhat dirty'\n",
            " 'Dirty'] \n",
            "\n",
            "Safety:  ['Neutral' 'Very safe' 'Somewhat safe' 'Very unsafe' 'Somewhat unsafe'] \n",
            "\n",
            "Satisfaction:  ['Very satisfied' 'Neutral' 'Somewhat satsified' 'Somewhat unsatisfied'\n",
            " 'Very unsatisfied'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vV_gQqilpW8H"
      },
      "source": [
        "üëÅÔ∏è‚Äçüó®Ô∏è Despues de observar lo que contiene cada una de las categorias, hemos detectado que la columna `Cleanliness` de `df_airlines` tiene una categoria inconsistentes que es ***Unacceptable***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SawfNAB9q2pX"
      },
      "source": [
        "üë∑‚Äç‚ôÄÔ∏è Ahora vamos a crear un conjunto de la columna `cleanliness` en `df_airlines` y encontremos la categoria inconsistente encontrando la **diferencia** en la columna `cleanliness` de `df_categories`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCSazqiBmtKz",
        "outputId": "30130626-0664-4d96-b3e7-f69a57a8d453"
      },
      "source": [
        "# Aplicamos la diferencia\n",
        "cat_clean = set(df_airlines['cleanliness']).difference(df_categories['cleanliness'])\n",
        "\n",
        "#Buscamos filas de df_airlines con un valor en cleanliness\n",
        "#que no este en df_categories\n",
        "cat_clean_rows = df_airlines['cleanliness'].isin(cat_clean)\n",
        "\n",
        "# Imprimimos las filas con categorias inconsistentes\n",
        "print(df_airlines[cat_clean_rows])\n",
        "\n",
        "# Imprimimos las filas solo con categorias consistentes\n",
        "print(df_airlines[~cat_clean_rows])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id        day  ...     safety        satisfaction\n",
            "4     2992  Wednesday  ...  Very safe  Somewhat satsified\n",
            "586   2920   Thursday  ...    Neutral    Very unsatisfied\n",
            "1816  2439  Wednesday  ...    Neutral             Neutral\n",
            "\n",
            "[3 rows x 12 columns]\n",
            "        id       day  ...         safety        satisfaction\n",
            "0     1351   Tuesday  ...        Neutral      Very satisfied\n",
            "1      373    Friday  ...      Very safe      Very satisfied\n",
            "2     2820  Thursday  ...  Somewhat safe             Neutral\n",
            "3     1157   Tuesday  ...      Very safe  Somewhat satsified\n",
            "5      634  Thursday  ...      Very safe      Very satisfied\n",
            "...    ...       ...  ...            ...                 ...\n",
            "2804  1475   Tuesday  ...        Neutral  Somewhat satsified\n",
            "2805  2222  Thursday  ...      Very safe      Very satisfied\n",
            "2806  2684    Friday  ...      Very safe      Very satisfied\n",
            "2807  2549   Tuesday  ...  Somewhat safe      Very satisfied\n",
            "2808  2162  Saturday  ...      Very safe  Somewhat satsified\n",
            "\n",
            "[2474 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hvRidpqwt61"
      },
      "source": [
        "üí° Vamos a examinar las columnas categ√≥ricas `dest_region` y `dest_size` del dataset `df_airlines`, y nos aseguraremos de que est√©n limpias y listas para el an√°lisis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WADSgF7IxFMj",
        "outputId": "9d714460-7138-40a2-8720-4e8cfca8d9dc"
      },
      "source": [
        "# Imprimimos los valores unicos de ambas columnas\n",
        "print('Dest Region: ', df_airlines['dest_region'].unique(), \"\\n\")\n",
        "print('Dest Size: ', df_airlines['dest_size'].unique(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dest Region:  ['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
            " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
            " 'Australia/New Zealand' 'middle east'] \n",
            "\n",
            "Dest Size:  ['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
            " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     '] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHfthIzjyFqY"
      },
      "source": [
        "Del resultado anterior podemos concluir los siguientes problemas:\n",
        "\n",
        "‚ö†Ô∏èLa columna `dest_region` tiene valores inconsistentes debido a las may√∫sculas y tiene un valor que debe reasignarse.\n",
        "\n",
        "‚ö†Ô∏èLa columna `dest_size` solo tiene valores inconsistentes debido a los espacios iniciales y finales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpcN61N5TG39"
      },
      "source": [
        "Para resolver los problemas que hemos dectetado procederemos a:<br>\n",
        "‚≠êCambiar las mayusculas de todos los valores de `dest_region` a minisculas.<br>\n",
        "‚≠êRemplazar `'eur'` con `'europe'` en `dest_region` usando el metodo `.replace()` <br>\n",
        "‚≠êQuitar los espacios en blancos de la columna `dest_size` usando el metodo `.strip()`<br>\n",
        "‚≠êVerificar que los cambios se hayan realizado con exito imprimiendo los valores unico de las columnas usando el metodo `.unique()`<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-T7WFRSzOPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98621cd7-809e-48be-d305-324ec09d70ae"
      },
      "source": [
        "df_airlines['dest_region'] = df_airlines['dest_region'].str.lower()\n",
        "\n",
        "df_airlines['dest_region'] = df_airlines['dest_region'].replace({'eur':'europe'})\n",
        "\n",
        "df_airlines['dest_size'] = df_airlines['dest_size'].str.strip()\n",
        "\n",
        "print('Dest Region: ', df_airlines['dest_region'].unique(), \"\\n\")\n",
        "print('Dest Size: ', df_airlines['dest_size'].unique(), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dest Region:  ['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
            " 'europe' 'central/south america' 'australia/new zealand'] \n",
            "\n",
            "Dest Size:  ['Hub' 'Small' 'Medium' 'Large'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgP79aOIXFh6"
      },
      "source": [
        "Para entender mejor a los encuestado, deseamos averiguar si existe una relaci√≥n entre ciertas respuestas y el d√≠a de la semana y el tiempo de espera en la puerta.\n",
        "\n",
        "el dataset `df_airlines` contiene las columnas `day` y `wait_min`, que son categ√≥ricas y num√©ricas respectivamente. La columna `day` contiene el d√≠a exacto en que se realiz√≥ un vuelo y `wait_min` la cantidad de minutos que los viajeros tardaron en esperar en la puerta de embarque. Para facilitar su an√°lisis, deseamos crear dos nuevas variables categ√≥ricas:\n",
        "\n",
        "`wait_type:` \n",
        "* `'short'` de 0 a 60 min \n",
        "* `'medium'`de 60 a 180 min \n",
        "* `'long'` mas de 180 min\n",
        "\n",
        "`day_week:`\n",
        "* `'weekday'`si el d√≠a est√° en el d√≠a de la semana\n",
        "* `'weekend'`si el d√≠a es en el fin de semana.\n",
        "\n",
        "Para resolverlo realizaremos los siguientes pasos:\n",
        "\n",
        "üëç Creamos los rangos y etiquetas para la columna `wait_type`<br>\n",
        "üëç Creamos la columna `wait_type` desde `wait_min` usando el metodo `pd.cut()`<br>\n",
        "üëç Creamos el diccionario `mapping` que ayudara a mapear a los dias de la semana `'weekday'` y a los dias del fin de semana`'weekend'`<br>\n",
        "Creamos la columna `day_week` usando `.replace()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suhssBgQYuZi"
      },
      "source": [
        "# Creamos los rangos para categoria\n",
        "label_ranges = [0, 60, 180, np.inf]\n",
        "label_names = ['short', 'medium', 'long']\n",
        "\n",
        "# Creamos la columna wait_type  \n",
        "df_airlines['wait_type'] = pd.cut(df_airlines['wait_min'], bins =label_ranges, \n",
        "                                labels = label_names)\n",
        "\n",
        "# Creamos el diccionario\n",
        "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
        "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
        "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
        "\n",
        "df_airlines['day_week'] = df_airlines['day'].replace(mappings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "NsI8viqZbtPn",
        "outputId": "b66182b5-39d5-4d34-96ca-9460c3092bcb"
      },
      "source": [
        "df_airlines.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>day</th>\n",
              "      <th>airline</th>\n",
              "      <th>destination</th>\n",
              "      <th>dest_region</th>\n",
              "      <th>dest_size</th>\n",
              "      <th>boarding_area</th>\n",
              "      <th>dept_time</th>\n",
              "      <th>wait_min</th>\n",
              "      <th>cleanliness</th>\n",
              "      <th>safety</th>\n",
              "      <th>satisfaction</th>\n",
              "      <th>wait_type</th>\n",
              "      <th>day_week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1351</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>UNITED INTL</td>\n",
              "      <td>KANSAI</td>\n",
              "      <td>asia</td>\n",
              "      <td>Hub</td>\n",
              "      <td>Gates 91-102</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>115.0</td>\n",
              "      <td>Clean</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Very satisfied</td>\n",
              "      <td>medium</td>\n",
              "      <td>weekday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>373</td>\n",
              "      <td>Friday</td>\n",
              "      <td>ALASKA</td>\n",
              "      <td>SAN JOSE DEL CABO</td>\n",
              "      <td>canada/mexico</td>\n",
              "      <td>Small</td>\n",
              "      <td>Gates 50-59</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Clean</td>\n",
              "      <td>Very safe</td>\n",
              "      <td>Very satisfied</td>\n",
              "      <td>medium</td>\n",
              "      <td>weekday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2820</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>DELTA</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>west us</td>\n",
              "      <td>Hub</td>\n",
              "      <td>Gates 40-48</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>70.0</td>\n",
              "      <td>Average</td>\n",
              "      <td>Somewhat safe</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>medium</td>\n",
              "      <td>weekday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1157</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>SOUTHWEST</td>\n",
              "      <td>LOS ANGELES</td>\n",
              "      <td>west us</td>\n",
              "      <td>Hub</td>\n",
              "      <td>Gates 20-39</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>190.0</td>\n",
              "      <td>Clean</td>\n",
              "      <td>Very safe</td>\n",
              "      <td>Somewhat satsified</td>\n",
              "      <td>long</td>\n",
              "      <td>weekday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2992</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>AMERICAN</td>\n",
              "      <td>MIAMI</td>\n",
              "      <td>east us</td>\n",
              "      <td>Hub</td>\n",
              "      <td>Gates 50-59</td>\n",
              "      <td>2018-12-31</td>\n",
              "      <td>559.0</td>\n",
              "      <td>Unacceptable</td>\n",
              "      <td>Very safe</td>\n",
              "      <td>Somewhat satsified</td>\n",
              "      <td>long</td>\n",
              "      <td>weekday</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id        day      airline  ...        satisfaction wait_type day_week\n",
              "0  1351    Tuesday  UNITED INTL  ...      Very satisfied    medium  weekday\n",
              "1   373     Friday       ALASKA  ...      Very satisfied    medium  weekday\n",
              "2  2820   Thursday        DELTA  ...             Neutral    medium  weekday\n",
              "3  1157    Tuesday    SOUTHWEST  ...  Somewhat satsified      long  weekday\n",
              "4  2992  Wednesday     AMERICAN  ...  Somewhat satsified      long  weekday\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6F5hFyswfCw"
      },
      "source": [
        "Y finalmente nuestros datos han quedado limpios y listos para ser utilizados. üéâüéâüéâ"
      ]
    }
  ]
}